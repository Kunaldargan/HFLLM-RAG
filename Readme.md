# ğŸ¥ HFLLM RAG Streamlit Med

**Health Records Management & Retrieval using Local LLM**

A secure, local-first Retrieval-Augmented Generation (RAG) application that allows wellness coaches and healthcare practitioners to:
- Upload, store, and manage medical records
- Ask personalized health-related questions
- Retrieve context-grounded answers using a Hugging Face-hosted LLaMA 3.2-Instruct model
- Minimize hallucinations and ensure clinical relevance with robust guardrails
- Highlight retrieved documents for better context understanding

![App Screenshot](assets/app_screenshot.png)

---

## ğŸš€ Features

- ğŸ” **RAG Pipeline**: Seamlessly integrates document retrieval with a powerful language model to generate grounded responses.
- ğŸ©º **Personalized QA**: Ask custom questions about patient history, lab reports, and treatment summaries.
- ğŸ“ **Medical Record Indexing**: Store structured and unstructured health records (PDFs, clinical notes, etc.).
- ğŸ§  **Local LLM**: Powered by Meta's LLaMA 3.2 3B-Instruct, hosted securely with Hugging Face Transformers.
- ğŸ”’ **Privacy & Compliance**: Designed for secure handling of sensitive medical data.
- ğŸ§° **Guardrails**: Contextual grounding, provenance tracking, and automated reasoning checks reduce hallucinations.

---

## ğŸ§± Tech Stack

| Component       | Tool/Library                        |
|----------------|-------------------------------------|
| UI             | Streamlit                           |
| Language Model | Hugging Face Transformers + LLaMA 3.2 |
| Retrieval      | FAISS / Elasticsearch               |
| NLP            | LangChain + Sentence Transformers   |
| Guardrails     | NVIDIA NeMo Guardrails              |

---

## ğŸ“‚ Project Structure

```
hfllm_rag_streamlit_med/
â”‚â”€â”€ app.py                        # Streamlit UI
â”‚â”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml              # Configuration file
â”‚â”€â”€ data/                          # Uploaded health records
â”‚   â”œâ”€â”€ patient_records/ 
â”‚   â”œâ”€â”€ medical_literature/
â”‚   â”œâ”€â”€ doctor_prescriptions/
â”‚   â”œâ”€â”€ medical_bills/
â”‚   â”œâ”€â”€ patient_history/
â”‚â”€â”€ models/
â”‚   â”œâ”€â”€ llama-3.2-3b-instruct-medical/ # Local LLM model
â”‚â”€â”€ utils/
â”‚   â”œâ”€â”€ data_processing.py         # OCR, preprocessing, chunking
â”‚   â”œâ”€â”€ retrieval.py               # Embedding + vector search
â”‚â”€â”€ requirements.txt               # Dependencies list
â”‚â”€â”€ README.md                      # Documentation
```

---

## ğŸ›  Installation Guide

### **Step 1: Clone the Repository**
```bash
git clone https://github.com/your-repo/hfllm_rag_streamlit_med.git
cd hfllm_rag_streamlit_med
```

### **Step 2: Create a Virtual Environment**
```bash
python -m venv env
source env/bin/activate  # On macOS/Linux
env\Scripts\activate      # On Windows
```

### **Step 3: Install Dependencies**
```bash
pip install -r requirements.txt
```

### **Step 4: Setup Configuration**
Modify `config/settings.yaml` to adjust API keys, retrieval parameters, or UI configurations.

---

## ğŸš€ Running the Application

### **Start the Streamlit Server**
```bash
streamlit run app.py
```
This will launch the user interface in your browser.

---

## ğŸ” How It Works

1. **Upload Documents**: PDFs or TXT files containing medical information.
2. **Automatic Chunking & Embedding**: Extracts relevant text and creates vector embeddings.
3. **Retrieval-Augmented Generation (RAG)**:
   - When a user inputs a query, itâ€™s converted into an embedding.
   - A similarity search is performed using FAISS or an alternative index.
   - The most relevant document chunks are retrieved and used for the final AI-generated response.
4. **Medical Guardrails**: Ensure reliable, contextually grounded responses with minimal hallucination.

---

## âš™ï¸ Configuration Options

You can modify parameters inside `config/settings.yaml`, such as:
```yaml
model_name: "llama-3.2-3b-instruct-medical"
top_k_results: 5
embedding_model: "sentence-transformers/all-mpnet-base-v2"
use_faiss: true
```

---

## ğŸ— Future Enhancements

- ğŸ”¥ **Enhanced PDF OCR Support**
- ğŸ¥ **Integration with existing EHR Systems**
- ğŸ” **Semantic Layer for Improved Query Interpretation**
- ğŸ”’ **Federated Learning for Personalized Retrieval**

---

This README gives a structured overview of setting up and using the project. Let me know if youâ€™d like any refinements or additional instructions! ğŸš€
